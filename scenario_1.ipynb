{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6fab088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['Country', 'Quality Score', 'SDGi', 'Life Expectancy', 'HDI',\n",
      "       'Per Capita GDP', 'Region', 'Income Group', 'Population (millions)',\n",
      "       'Cropland Footprint', 'Grazing Footprint', 'Forest Product Footprint',\n",
      "       'Fish Footprint', 'Built up land', 'Carbon Footprint',\n",
      "       'Total Ecological Footprint (Production)', 'Cropland Footprint.1',\n",
      "       'Grazing Footprint.1', 'Forest Product Footprint.1', 'Fish Footprint.1',\n",
      "       'Built up land.1', 'Carbon Footprint.1',\n",
      "       'Total Ecological Footprint (Consumption)', 'Cropland', 'Grazing land',\n",
      "       'Forest land', 'Fishing ground', 'Built up land.2',\n",
      "       'Total biocapacity ', 'Ecological (Deficit) or Reserve',\n",
      "       'Number of Earths required', 'Number of Countries required',\n",
      "       'actual \\nCountry Overshoot Day \\n2018', 'Overshoot_day_month'],\n",
      "      dtype='object')\n",
      "0       nan-nan\n",
      "1      11.0-1.0\n",
      "2       9.0-2.0\n",
      "3       nan-nan\n",
      "4       5.0-3.0\n",
      "         ...   \n",
      "179    8.0-28.0\n",
      "180    9.0-10.0\n",
      "181     nan-nan\n",
      "182     nan-nan\n",
      "183     nan-nan\n",
      "Name: Overshoot_day_month, Length: 184, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Importation de la base de donnée, une seule feuille dans le fichier donc pas de pbl\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"NA.xlsx\")\n",
    "print(type(df))  # vérifier que c'est bien un DataFrame\n",
    "\n",
    "# Conversion en datetime\n",
    "Y_col = 'actual \\nCountry Overshoot Day \\n2018'\n",
    "df[Y_col] = pd.to_datetime(df[Y_col], errors='coerce')\n",
    "\n",
    "# Extraire jour et mois\n",
    "df['day'] = df[Y_col].dt.day\n",
    "df['month'] = df[Y_col].dt.month\n",
    "\n",
    "# Concaténer mois et jour en format \"MM-DD\"\n",
    "df['Overshoot_day_month'] = df['month'].astype(str).str.zfill(2) + \"-\" + df['day'].astype(str).str.zfill(2)\n",
    "\n",
    "df = df.drop(columns=['day', 'month'])\n",
    "\n",
    "print(df.columns) \n",
    "print(df['Overshoot_day_month'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb21b9c",
   "metadata": {},
   "source": [
    "Afficher le nombre de lignes et de colonnes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e431bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "# nombre de lignes :\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18908d1c",
   "metadata": {},
   "source": [
    "Il y a donc  184 pays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bca77178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "# nombre de lignes :\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd80348",
   "metadata": {},
   "source": [
    "Il y a donc 33 colonnes + Overshoot_day_month\n",
    "\n",
    "Création de la vatiable de réponse Y et de la matrice de variables explicatives : X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e19b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'Quality Score', 'SDGi', 'Life Expectancy', 'HDI', 'Per Capita GDP', 'Region', 'Income Group', 'Population (millions)', 'Cropland Footprint', 'Grazing Footprint', 'Forest Product Footprint', 'Fish Footprint', 'Built up land', 'Carbon Footprint', 'Total Ecological Footprint (Production)', 'Cropland Footprint.1', 'Grazing Footprint.1', 'Forest Product Footprint.1', 'Fish Footprint.1', 'Built up land.1', 'Carbon Footprint.1', 'Total Ecological Footprint (Consumption)', 'Cropland', 'Grazing land', 'Forest land', 'Fishing ground', 'Built up land.2', 'Total biocapacity ', 'Ecological (Deficit) or Reserve', 'Number of Earths required', 'Number of Countries required']\n"
     ]
    }
   ],
   "source": [
    "Y_col = \"Overshoot_day_month\"\n",
    "df['id'] = df.index + 1\n",
    "\n",
    "# X_cols ne prend pas la colonne nom_pays + prend l id pour retrouver les pays\n",
    "cols_to_include = df.columns[1:-3] # pas les 2 overshoulday\n",
    "\n",
    "cols = [col for col in cols_to_include if col != Y_col]\n",
    "\n",
    "X_cols = ['id'] + list(cols_to_include)\n",
    "\n",
    "print(len(X_cols)) # si 32 alors ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e017c17",
   "metadata": {},
   "source": [
    "Génération du jeu de données du S1, sans aucune ligne contenant au mins une NA : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "55b2b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# on prend df en on supprime les lignes ou il y a des données NA parmis les X ou Y :\n",
    "\n",
    "df[\"Per Capita GDP\"] = (\n",
    "    df[\"Per Capita GDP\"]\n",
    "    .replace(\"-\", np.nan)\n",
    ")\n",
    "\n",
    "df[\"Overshoot_day_month\"] = (\n",
    "    df[\"Overshoot_day_month\"]\n",
    "    .replace(\"nan-nan\", np.nan)\n",
    ")\n",
    "\n",
    "df[\"Per Capita GDP\"] = pd.to_numeric(\n",
    "    df[\"Per Capita GDP\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "s_un = df.dropna(subset=X_cols + [Y_col])\n",
    "\n",
    "print(len(s_un))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749c8be",
   "metadata": {},
   "source": [
    "Nous avons donc 109 lignes\n",
    "\n",
    "Pour réaliser les prédictions, commençons par séparer le jeu de données en X et Y :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1332d348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality Score\n",
      "Region\n",
      "Income Group\n",
      "1       11.0-1.0\n",
      "2        9.0-2.0\n",
      "5       6.0-22.0\n",
      "6      10.0-29.0\n",
      "7       3.0-21.0\n",
      "         ...    \n",
      "173     3.0-11.0\n",
      "174     5.0-17.0\n",
      "175     3.0-11.0\n",
      "177     10.0-9.0\n",
      "180     9.0-10.0\n",
      "Name: Overshoot_day_month, Length: 106, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Séparation X / y\n",
    "X = s_un[X_cols]\n",
    "y = s_un[Y_col]\n",
    "\n",
    "# Avant d'apprendre, il faut gerer les colonnes non numeriques : \n",
    "for col in X_cols: \n",
    "    if df[col].dtype == 'object': \n",
    "        print(col) \n",
    "        \n",
    "# Il y a donc 3 colonnes a gerer, elles sont catégorielles :\n",
    "\n",
    "categorical_cols = ['Quality Score', 'Region', 'Income Group']\n",
    "\n",
    "# Encodage\n",
    "X_encoded = pd.get_dummies(\n",
    "    X,\n",
    "    columns=categorical_cols,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15864e62",
   "metadata": {},
   "source": [
    "Nous avons maintenant X_encoded, regardons sont nombre de colonnes, normalement il a toujours 109 lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "966d532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(X_encoded))\n",
    "print(len(X_encoded.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "902b5338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       11.0-1.0\n",
      "2        9.0-2.0\n",
      "5       6.0-22.0\n",
      "6      10.0-29.0\n",
      "7       3.0-21.0\n",
      "         ...    \n",
      "173     3.0-11.0\n",
      "174     5.0-17.0\n",
      "175     3.0-11.0\n",
      "177     10.0-9.0\n",
      "180     9.0-10.0\n",
      "Name: Overshoot_day_month, Length: 106, dtype: object\n",
      "1      305\n",
      "2      245\n",
      "5      173\n",
      "6      302\n",
      "7       80\n",
      "      ... \n",
      "173     70\n",
      "174    137\n",
      "175     70\n",
      "177    282\n",
      "180    253\n",
      "Name: Overshoot_day_month, Length: 106, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Avant tout, convertir la target en numérique :\n",
    "import pandas as pd\n",
    "\n",
    "def month_day_to_numeric(s):\n",
    "    \"\"\"Convert 'month-day' string with possible floats to day-of-year (year=2018).\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    try:\n",
    "        # séparer mois et jour\n",
    "        month_str, day_str = s.split('-')\n",
    "        # convertir en float puis en int\n",
    "        month = int(float(month_str))\n",
    "        day = int(float(day_str))\n",
    "        # créer la date avec année 2018\n",
    "        dt = pd.Timestamp(year=2018, month=month, day=day)\n",
    "        return dt.dayofyear\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Appliquer à la colonne\n",
    "print(y)\n",
    "y = y.apply(month_day_to_numeric)\n",
    "\n",
    "# Vérifier\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e67300",
   "metadata": {},
   "source": [
    "Il y a donc 41 colonnes, c'est bormale car en encodant, nous en avons créé de nouvelles\n",
    "\n",
    "Maintenant que c'est fait, je split mon jeu de données afin de créer le train et le test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d905f324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype('bool') dtype('int64') dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, \n",
    "    y, \n",
    "    # je separe en 20% test et 80% train\n",
    "    test_size=0.2, \n",
    "    # j'ai mit une graine afin d'avoir toujours les mêmes résultats\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "\n",
    "print(np.unique(X_train.dtypes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ef6e0",
   "metadata": {},
   "source": [
    "Je crée le modèle linéaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1a088241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170.26701075  98.86889432 173.77872591 213.34669055 102.7275402\n",
      " 104.58243704 193.25718185 110.7334991  214.63618827  11.08648031\n",
      " 137.80238956  62.96083463 348.63989082 179.5519225  217.83412389\n",
      " 253.15310785  98.86377609 131.80439257 327.53294709 239.11906978\n",
      " 308.20181223 132.86276594]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "train = model.fit(X_train, y_train)\n",
    "\n",
    "# prédiction sur les données de X_test\n",
    "y_pred = train.predict(X_test) \n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5303c9ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[224], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Matrice de confusion\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrice de confusion :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame(conf_matrix))\n",
      "File \u001b[1;32mc:\\Users\\annac\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\annac\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:340\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03mBy definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m(np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[1;32m--> 340\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\annac\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    109\u001b[0m             type_true, type_pred\n\u001b[0;32m    110\u001b[0m         )\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(pd.DataFrame(conf_matrix))\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
